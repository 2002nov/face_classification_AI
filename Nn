import cv2 as cv
from ultralytics import YOLO
import os
import torch
from torchvision import transforms
from PIL import Image  # Add this import statement


# Load YOLOv8 model
detect_model = YOLO('/home/rvp/Work_Student2024/TrainAi/yolov8l-face.pt')
classify_model = '/home/rvp/Work_Student2024/Bow/train15#/weights/best.pt'
class_dict = {0: 'Angry', 1: 'Bored', 2: 'Confused', 3: 'Cool', 4: 'Errrr', 5: 'Funny', 6: 'Happy', 7: 'Normal', 8: 'Proud', 9: 'Sad', 10: 'Scared', 11: 'Shy', 12: 'Sigh', 13: 'Superangry', 14: 'Surprised', 15: 'Suspicious', 16: 'Unhappy', 17: 'Worried', 18: 'sweet', 19: 'tricky'}


# Define preprocessing transformation
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Open video file
cap = cv.VideoCapture('/home/rvp/Work_Student2024/Bow/คำต้องห้าม.mp4')

# Create a directory to save the detected faces
output_dir = '/home/rvp/Work_Student2024/Bow/picture'
os.makedirs(output_dir, exist_ok=True)

frame_counter = 0
